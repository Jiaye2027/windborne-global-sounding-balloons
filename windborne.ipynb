{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T05:37:19.904699Z",
     "iopub.status.busy": "2025-03-05T05:37:19.904259Z",
     "iopub.status.idle": "2025-03-05T05:37:34.485682Z",
     "shell.execute_reply": "2025-03-05T05:37:34.484104Z",
     "shell.execute_reply.started": "2025-03-05T05:37:19.904661Z"
    }
   },
   "outputs": [],
   "source": [
    "pip install langchain_openai langchain langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T05:37:34.487745Z",
     "iopub.status.busy": "2025-03-05T05:37:34.487426Z",
     "iopub.status.idle": "2025-03-05T05:37:39.580090Z",
     "shell.execute_reply": "2025-03-05T05:37:39.578849Z",
     "shell.execute_reply.started": "2025-03-05T05:37:34.487694Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from scipy.interpolate import interp1d\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def fetch_windborne_data(hours=24):\n",
    "    all_data = {}\n",
    "    for h in range(hours):\n",
    "        url = f\"https://a.windbornesystems.com/treasure/{h:02d}.json\"\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            try:\n",
    "                data = response.json()\n",
    "                if isinstance(data, list) and all(isinstance(item, list) and len(item) == 3 for item in data):\n",
    "                    all_data[h] = np.array(data)\n",
    "                else:\n",
    "                    print(f\"Warning: Skipping malformed data from {url}\")\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON from {url}: {e}\")\n",
    "        else:\n",
    "            print(f\"Failed to fetch {url}, status code: {response.status_code}\")\n",
    "\n",
    "    if not all_data:\n",
    "        print(\"No valid data collected.\")\n",
    "        return None\n",
    "    \n",
    "    # Ensure data is structured as (hours, balloons, coordinates) only for existing hours\n",
    "    num_balloons = max(arr.shape[0] for arr in all_data.values())\n",
    "    structured_data = np.full((len(all_data), num_balloons, 3), np.nan)\n",
    "    \n",
    "    for i, (h, data) in enumerate(all_data.items()):\n",
    "        structured_data[i, :data.shape[0], :] = data\n",
    "    \n",
    "    # Fill missing values with column mean\n",
    "    for d in range(3):  # Iterate over x, y, z coordinates\n",
    "        valid_mask = ~np.isnan(structured_data[:, :, d])\n",
    "        if valid_mask.any():  # If at least one valid value exists\n",
    "            mean_value = np.nanmean(structured_data[:, :, d])\n",
    "            structured_data[:, :, d] = np.where(np.isnan(structured_data[:, :, d]), mean_value, structured_data[:, :, d])\n",
    "    \n",
    "    return structured_data\n",
    "\n",
    "all_positions = fetch_windborne_data()\n",
    "\n",
    "if all_positions is not None:\n",
    "    print(\"Data Shape (after full interpolation):\", all_positions.shape)\n",
    "    print(\"Any NaN remaining?\", np.isnan(all_positions).any())\n",
    "else:\n",
    "    print(\"No valid data available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T05:37:39.582657Z",
     "iopub.status.busy": "2025-03-05T05:37:39.582253Z",
     "iopub.status.idle": "2025-03-05T05:38:28.024347Z",
     "shell.execute_reply": "2025-03-05T05:38:28.023059Z",
     "shell.execute_reply.started": "2025-03-05T05:37:39.582627Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def process_sequences(data, time_steps=5):\n",
    "    \"\"\"Prepare LSTM sequences for training, ensuring correct order.\"\"\"\n",
    "    num_balloons = data.shape[1]\n",
    "    X, y = [], []\n",
    "    scalers = [MinMaxScaler() for _ in range(num_balloons)]\n",
    "\n",
    "    for i in range(num_balloons):\n",
    "        balloon_data = data[:, i, :][::-1]  # Reverse order: [08, 07, ..., 00]\n",
    "        balloon_data = scalers[i].fit_transform(balloon_data)\n",
    "\n",
    "        # Generate time-step sequences\n",
    "        for j in range(len(balloon_data) - time_steps):\n",
    "            X.append(balloon_data[j:j+time_steps])\n",
    "            y.append(balloon_data[j+time_steps])\n",
    "\n",
    "    return np.array(X), np.array(y), scalers\n",
    "\n",
    "# Prepare LSTM sequences\n",
    "time_steps = 5\n",
    "X, y, scalers = process_sequences(all_positions, time_steps)\n",
    "print(\"LSTM Input Shape:\", X.shape)  # Expected: (num_samples, time_steps, 3)\n",
    "\n",
    "# Define Early Stopping\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "\n",
    "# Define LSTM Model\n",
    "model = Sequential([\n",
    "    LSTM(64, return_sequences=True, activation=\"relu\", input_shape=(time_steps, 3)),\n",
    "    LSTM(32, return_sequences=False, activation=\"relu\"),\n",
    "    Dense(16, activation=\"relu\"),\n",
    "    Dense(3)  # Predicts (lat, lon, alt)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001, clipnorm=1.0), loss=\"mse\")\n",
    "\n",
    "# Train Model\n",
    "history = model.fit(X, y, epochs=30, batch_size=16, validation_split=0.1, callbacks=[early_stop])\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "mse = mean_squared_error(y.reshape(-1, 3), y_pred.reshape(-1, 3))\n",
    "r2 = r2_score(y.reshape(-1, 3), y_pred.reshape(-1, 3))\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse:.6f}\")\n",
    "print(f\"R² Score: {r2:.6f}\")\n",
    "\n",
    "def predict_next_position(model, all_positions, scalers, time_steps=5):\n",
    "    \"\"\"Predict the next step using the latest available data from each balloon.\"\"\"\n",
    "    num_balloons = len(scalers)\n",
    "    predicted_next_real = []\n",
    "\n",
    "    for i in range(num_balloons):\n",
    "        balloon_data = all_positions[:, i, :][::-1]  # Reverse to get the latest first\n",
    "        balloon_data_scaled = scalers[i].transform(balloon_data)\n",
    "        latest_sequence = balloon_data_scaled[:time_steps].reshape(1, time_steps, 3)\n",
    "\n",
    "        predicted_scaled = model.predict(latest_sequence, verbose=0)\n",
    "        predicted_real = scalers[i].inverse_transform(predicted_scaled)\n",
    "        predicted_next_real.append(predicted_real)\n",
    "\n",
    "    return np.array(predicted_next_real)\n",
    "\n",
    "# Predict the next time step\n",
    "predicted_next_position = predict_next_position(model, all_positions, scalers, time_steps)\n",
    "\n",
    "print(\"Predicted Next Positions (Lat, Lon, Alt):\")\n",
    "print(predicted_next_position)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-05T05:45:57.922134Z",
     "iopub.status.busy": "2025-03-05T05:45:57.921674Z",
     "iopub.status.idle": "2025-03-05T05:45:59.558910Z",
     "shell.execute_reply": "2025-03-05T05:45:59.557582Z",
     "shell.execute_reply.started": "2025-03-05T05:45:57.922100Z"
    }
   },
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if OPENAI_API_KEY is None:\n",
    "    raise ValueError(\"❌ OPENAI_API_KEY is not set. Check your GitHub Secrets.\")\n",
    "\n",
    "template = \"\"\"You are an operational analyst for a weather balloon company. Analyze the data of \n",
    "balloon positions over 24H: {all_positions}, LSTM prediction: {LSTM prediction}, pred next position: {pred next position}\n",
    "\n",
    "Extract 3 key insights, such as:\n",
    "- Spatial clusters indicating wind patterns\n",
    "- Anomalies (e.g., balloons stuck in one area)\n",
    "- Suggestions for optimizing future launches\n",
    "Format the response as a bullet-point report.\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# Generate insights\n",
    "chain = prompt | model\n",
    "report = chain.invoke({\"all_positions\": str(all_positions), \"LSTM prediction\": str(y_pred), \"pred next position\": str(predicted_next_position)})\n",
    "print(report.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insights_text = report.content if isinstance(report.content, str) else str(report.content)\n",
    "\n",
    "html_output = f\"\"\"\n",
    "<html><head><title>Windborne Balloon Analysis</title></head>\n",
    "<body>\n",
    "    <h1>Windborne Balloon Analysis</h1>\n",
    "    <p><strong>Mean Squared Error (MSE):</strong> {mse:.6f}</p>\n",
    "    <p><strong>R² Score:</strong> {r2:.6f}</p>\n",
    "    <h2>Predicted Next Position:</h2>\n",
    "    <pre>{predicted_next_position.tolist()}</pre>\n",
    "    <h2>Insights:</h2>\n",
    "    <pre>{insights_text}</pre>  <!-- Ensures correct display -->\n",
    "</body></html>\n",
    "\"\"\"\n",
    "\n",
    "# Write HTML file\n",
    "with open(\"docs/index.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(html_output)\n",
    "\n",
    "print(\"✅ Output saved in docs/index.html\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
