{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install langchain_openai langchain langchain_community","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T05:37:19.904259Z","iopub.execute_input":"2025-03-05T05:37:19.904699Z","iopub.status.idle":"2025-03-05T05:37:34.485682Z","shell.execute_reply.started":"2025-03-05T05:37:19.904661Z","shell.execute_reply":"2025-03-05T05:37:34.484104Z"}},"outputs":[{"name":"stdout","text":"Collecting langchain_openai\n  Downloading langchain_openai-0.3.7-py3-none-any.whl.metadata (2.3 kB)\nRequirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.12)\nCollecting langchain_community\n  Downloading langchain_community-0.3.19-py3-none-any.whl.metadata (2.4 kB)\nCollecting langchain-core<1.0.0,>=0.3.39 (from langchain_openai)\n  Downloading langchain_core-0.3.41-py3-none-any.whl.metadata (5.9 kB)\nCollecting openai<2.0.0,>=1.58.1 (from langchain_openai)\n  Downloading openai-1.65.3-py3-none-any.whl.metadata (27 kB)\nRequirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.9.0)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.12)\nCollecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\nRequirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.3)\nRequirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.3)\nRequirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.11.0a2)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\nCollecting langchain\n  Downloading langchain-0.3.20-py3-none-any.whl.metadata (7.7 kB)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\nCollecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\nCollecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\nCollecting langchain-text-splitters<1.0.0,>=0.3.6 (from langchain)\n  Downloading langchain_text_splitters-0.3.6-py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.39->langchain_openai) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.39->langchain_openai) (24.2)\nRequirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.39->langchain_openai) (4.12.2)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.12)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.4->langchain) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.4->langchain) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.4->langchain) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.4->langchain) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.4->langchain) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.4->langchain) (2.4.1)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (3.7.1)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.9.0)\nRequirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.8.2)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.3.1)\nRequirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (4.67.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.29.0)\nCollecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain_openai) (1.2.2)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.39->langchain_openai) (3.0.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2,>=1.22.4->langchain) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2,>=1.22.4->langchain) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2,>=1.22.4->langchain) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2,>=1.22.4->langchain) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2,>=1.22.4->langchain) (2024.2.0)\nDownloading langchain_openai-0.3.7-py3-none-any.whl (55 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_community-0.3.19-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading langchain-0.3.20-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\nDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\nDownloading langchain_core-0.3.41-py3-none-any.whl (415 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m415.1/415.1 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.3.6-py3-none-any.whl (31 kB)\nDownloading openai-1.65.3-py3-none-any.whl (472 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\nDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\nInstalling collected packages: python-dotenv, httpx-sse, async-timeout, pydantic-settings, openai, langchain-core, langchain-text-splitters, langchain_openai, langchain, langchain_community\n  Attempting uninstall: async-timeout\n    Found existing installation: async-timeout 5.0.1\n    Uninstalling async-timeout-5.0.1:\n      Successfully uninstalled async-timeout-5.0.1\n  Attempting uninstall: openai\n    Found existing installation: openai 1.57.4\n    Uninstalling openai-1.57.4:\n      Successfully uninstalled openai-1.57.4\n  Attempting uninstall: langchain-core\n    Found existing installation: langchain-core 0.3.25\n    Uninstalling langchain-core-0.3.25:\n      Successfully uninstalled langchain-core-0.3.25\n  Attempting uninstall: langchain-text-splitters\n    Found existing installation: langchain-text-splitters 0.3.3\n    Uninstalling langchain-text-splitters-0.3.3:\n      Successfully uninstalled langchain-text-splitters-0.3.3\n  Attempting uninstall: langchain\n    Found existing installation: langchain 0.3.12\n    Uninstalling langchain-0.3.12:\n      Successfully uninstalled langchain-0.3.12\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed async-timeout-4.0.3 httpx-sse-0.4.0 langchain-0.3.20 langchain-core-0.3.41 langchain-text-splitters-0.3.6 langchain_community-0.3.19 langchain_openai-0.3.7 openai-1.65.3 pydantic-settings-2.8.1 python-dotenv-1.0.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import requests\nimport numpy as np\nimport json\nfrom scipy.interpolate import interp1d\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_openai import ChatOpenAI\n\ndef fetch_windborne_data(hours=24):\n    all_data = {}\n    for h in range(hours):\n        url = f\"https://a.windbornesystems.com/treasure/{h:02d}.json\"\n        response = requests.get(url)\n        if response.status_code == 200:\n            try:\n                data = response.json()\n                if isinstance(data, list) and all(isinstance(item, list) and len(item) == 3 for item in data):\n                    all_data[h] = np.array(data)\n                else:\n                    print(f\"Warning: Skipping malformed data from {url}\")\n            except json.JSONDecodeError as e:\n                print(f\"Error decoding JSON from {url}: {e}\")\n        else:\n            print(f\"Failed to fetch {url}, status code: {response.status_code}\")\n\n    if not all_data:\n        print(\"No valid data collected.\")\n        return None\n    \n    # Ensure data is structured as (hours, balloons, coordinates) only for existing hours\n    num_balloons = max(arr.shape[0] for arr in all_data.values())\n    structured_data = np.full((len(all_data), num_balloons, 3), np.nan)\n    \n    for i, (h, data) in enumerate(all_data.items()):\n        structured_data[i, :data.shape[0], :] = data\n    \n    # Fill missing values with column mean\n    for d in range(3):  # Iterate over x, y, z coordinates\n        valid_mask = ~np.isnan(structured_data[:, :, d])\n        if valid_mask.any():  # If at least one valid value exists\n            mean_value = np.nanmean(structured_data[:, :, d])\n            structured_data[:, :, d] = np.where(np.isnan(structured_data[:, :, d]), mean_value, structured_data[:, :, d])\n    \n    return structured_data\n\nall_positions = fetch_windborne_data()\n\nif all_positions is not None:\n    print(\"Data Shape (after full interpolation):\", all_positions.shape)\n    print(\"Any NaN remaining?\", np.isnan(all_positions).any())\nelse:\n    print(\"No valid data available.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T05:37:34.487426Z","iopub.execute_input":"2025-03-05T05:37:34.487745Z","iopub.status.idle":"2025-03-05T05:37:39.580090Z","shell.execute_reply.started":"2025-03-05T05:37:34.487694Z","shell.execute_reply":"2025-03-05T05:37:39.578849Z"}},"outputs":[{"name":"stdout","text":"Failed to fetch https://a.windbornesystems.com/treasure/05.json, status code: 404\nError decoding JSON from https://a.windbornesystems.com/treasure/06.json: Extra data: line 6 column 6 (char 93)\nError decoding JSON from https://a.windbornesystems.com/treasure/07.json: Extra data: line 6 column 6 (char 94)\nFailed to fetch https://a.windbornesystems.com/treasure/08.json, status code: 404\nFailed to fetch https://a.windbornesystems.com/treasure/09.json, status code: 404\nFailed to fetch https://a.windbornesystems.com/treasure/10.json, status code: 404\nFailed to fetch https://a.windbornesystems.com/treasure/11.json, status code: 404\nFailed to fetch https://a.windbornesystems.com/treasure/14.json, status code: 404\nError decoding JSON from https://a.windbornesystems.com/treasure/15.json: Extra data: line 6 column 6 (char 92)\nFailed to fetch https://a.windbornesystems.com/treasure/16.json, status code: 404\nFailed to fetch https://a.windbornesystems.com/treasure/17.json, status code: 404\nFailed to fetch https://a.windbornesystems.com/treasure/18.json, status code: 404\nFailed to fetch https://a.windbornesystems.com/treasure/19.json, status code: 404\nError decoding JSON from https://a.windbornesystems.com/treasure/20.json: Extra data: line 6 column 6 (char 93)\nFailed to fetch https://a.windbornesystems.com/treasure/21.json, status code: 404\nError decoding JSON from https://a.windbornesystems.com/treasure/22.json: Extra data: line 6 column 6 (char 95)\nFailed to fetch https://a.windbornesystems.com/treasure/23.json, status code: 404\nData Shape (after full interpolation): (7, 1000, 3)\nAny NaN remaining? False\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.metrics import mean_squared_error, r2_score\n\ndef process_sequences(data, time_steps=5):\n    \"\"\"Prepare LSTM sequences for training, ensuring correct order.\"\"\"\n    num_balloons = data.shape[1]\n    X, y = [], []\n    scalers = [MinMaxScaler() for _ in range(num_balloons)]\n\n    for i in range(num_balloons):\n        balloon_data = data[:, i, :][::-1]  # Reverse order: [08, 07, ..., 00]\n        balloon_data = scalers[i].fit_transform(balloon_data)\n\n        # Generate time-step sequences\n        for j in range(len(balloon_data) - time_steps):\n            X.append(balloon_data[j:j+time_steps])\n            y.append(balloon_data[j+time_steps])\n\n    return np.array(X), np.array(y), scalers\n\n# Prepare LSTM sequences\ntime_steps = 5\nX, y, scalers = process_sequences(all_positions, time_steps)\nprint(\"LSTM Input Shape:\", X.shape)  # Expected: (num_samples, time_steps, 3)\n\n# Define Early Stopping\nearly_stop = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n\n# Define LSTM Model\nmodel = Sequential([\n    LSTM(64, return_sequences=True, activation=\"relu\", input_shape=(time_steps, 3)),\n    LSTM(32, return_sequences=False, activation=\"relu\"),\n    Dense(16, activation=\"relu\"),\n    Dense(3)  # Predicts (lat, lon, alt)\n])\n\nmodel.compile(optimizer=Adam(learning_rate=0.001, clipnorm=1.0), loss=\"mse\")\n\n# Train Model\nhistory = model.fit(X, y, epochs=30, batch_size=16, validation_split=0.1, callbacks=[early_stop])\n\ny_pred = model.predict(X)\nmse = mean_squared_error(y.reshape(-1, 3), y_pred.reshape(-1, 3))\nr2 = r2_score(y.reshape(-1, 3), y_pred.reshape(-1, 3))\n\nprint(f\"Mean Squared Error (MSE): {mse:.6f}\")\nprint(f\"R² Score: {r2:.6f}\")\n\ndef predict_next_position(model, all_positions, scalers, time_steps=5):\n    \"\"\"Predict the next step using the latest available data from each balloon.\"\"\"\n    num_balloons = len(scalers)\n    predicted_next_real = []\n\n    for i in range(num_balloons):\n        balloon_data = all_positions[:, i, :][::-1]  # Reverse to get the latest first\n        balloon_data_scaled = scalers[i].transform(balloon_data)\n        latest_sequence = balloon_data_scaled[:time_steps].reshape(1, time_steps, 3)\n\n        predicted_scaled = model.predict(latest_sequence, verbose=0)\n        predicted_real = scalers[i].inverse_transform(predicted_scaled)\n        predicted_next_real.append(predicted_real)\n\n    return np.array(predicted_next_real)\n\n# Predict the next time step\npredicted_next_position = predict_next_position(model, all_positions, scalers, time_steps)\n\nprint(\"Predicted Next Positions (Lat, Lon, Alt):\")\nprint(predicted_next_position)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T05:37:39.582253Z","iopub.execute_input":"2025-03-05T05:37:39.582657Z","iopub.status.idle":"2025-03-05T05:38:28.024347Z","shell.execute_reply.started":"2025-03-05T05:37:39.582627Z","shell.execute_reply":"2025-03-05T05:38:28.023059Z"}},"outputs":[{"name":"stdout","text":"LSTM Input Shape: (2000, 5, 3)\nEpoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.3026 - val_loss: 0.1386\nEpoch 2/30\n\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0897 - val_loss: 0.0384\nEpoch 3/30\n\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0365 - val_loss: 0.0298\nEpoch 4/30\n\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0296 - val_loss: 0.0195\nEpoch 5/30\n\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0208 - val_loss: 0.0174\nEpoch 6/30\n\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0157 - val_loss: 0.0198\nEpoch 7/30\n\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0137 - val_loss: 0.0143\nEpoch 8/30\n\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0124 - val_loss: 0.0152\nEpoch 9/30\n\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0125 - val_loss: 0.0180\nEpoch 10/30\n\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0130 - val_loss: 0.0132\nEpoch 11/30\n\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0119 - val_loss: 0.0123\nEpoch 12/30\n\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0117 - val_loss: 0.0101\nEpoch 13/30\n\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0092 - val_loss: 0.0097\nEpoch 14/30\n\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0110 - val_loss: 0.0100\nEpoch 15/30\n\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0092 - val_loss: 0.0103\nEpoch 16/30\n\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0103 - val_loss: 0.0123\nEpoch 17/30\n\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0091 - val_loss: 0.0108\nEpoch 18/30\n\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0097 - val_loss: 0.0106\nEpoch 19/30\n\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0087 - val_loss: 0.0121\nEpoch 20/30\n\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0076 - val_loss: 0.0106\nEpoch 21/30\n\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0078 - val_loss: 0.0101\nEpoch 22/30\n\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0076 - val_loss: 0.0099\nEpoch 23/30\n\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0082 - val_loss: 0.0092\nEpoch 24/30\n\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0081 - val_loss: 0.0105\nEpoch 25/30\n\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0074 - val_loss: 0.0092\nEpoch 26/30\n\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0049 - val_loss: 0.0102\nEpoch 27/30\n\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0088 - val_loss: 0.0102\nEpoch 28/30\n\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0074 - val_loss: 0.0102\nEpoch 29/30\n\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0071 - val_loss: 0.0099\nEpoch 30/30\n\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0092 - val_loss: 0.0084\n\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\nMean Squared Error (MSE): 0.006445\nR² Score: 0.967793\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"template = \"\"\"You are an operational analyst for a weather balloon company. Analyze the data of \nballoon positions over 24H: {all_positions}, LSTM prediction: {LSTM prediction}, pred next position: {pred next position}\n\nExtract 3 key insights, such as:\n- Spatial clusters indicating wind patterns\n- Anomalies (e.g., balloons stuck in one area)\n- Suggestions for optimizing future launches\nFormat the response as a bullet-point report.\"\"\"\nprompt = ChatPromptTemplate.from_template(template)\nmodel = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-3.5-turbo\")\n\n# Generate insights\nchain = prompt | model\nreport = chain.invoke({\"all_positions\": str(all_positions), \"LSTM prediction\": str(y_pred), \"pred next position\": str(predicted_next_position)})\nprint(report.content)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-05T05:45:57.921674Z","iopub.execute_input":"2025-03-05T05:45:57.922134Z","iopub.status.idle":"2025-03-05T05:45:59.558910Z","shell.execute_reply.started":"2025-03-05T05:45:57.922100Z","shell.execute_reply":"2025-03-05T05:45:59.557582Z"}},"outputs":[{"name":"stdout","text":"- Spatial clusters indicating wind patterns: By analyzing the data of balloon positions over 24 hours, we can identify spatial clusters that indicate wind patterns. These clusters may help in understanding the direction and intensity of winds at different altitudes.\n\n- Anomalies: There do not seem to be any significant anomalies in the data, indicating that the balloons are not stuck in one particular area or facing any unexpected issues during the 24-hour period. This suggests that the balloon launches are functioning smoothly.\n\n- Suggestions for optimizing future launches: Based on the LSTM predictions for the next positions of the balloons, we can optimize future launches by adjusting the launch locations or timings to minimize travel time and maximize data collection efficiency. Additionally, utilizing the spatial clusters identified in the data can help in planning more strategic launch locations to gather diverse weather data.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Save results\noutput = {\n    \"mse\": mse,\n    \"r2\": r2,\n    \"predicted_next_position\": predicted_next_position.tolist(),\n    \"insights\": report.content\n}\nwith open(\"docs/output.json\", \"w\") as f:\n    json.dump(output, f, indent=4)\n\nhtml_output = f\"\"\"\n<html><head><title>Windborne Balloon Analysis</title></head>\n<body>\n    <h1>Windborne Balloon Analysis</h1>\n    <p><strong>Mean Squared Error (MSE):</strong> {mse:.6f}</p>\n    <p><strong>R² Score:</strong> {r2:.6f}</p>\n    <h2>Predicted Next Position:</h2>\n    <pre>{predicted_next_position.tolist()}</pre>\n    <h2>Insights:</h2>\n    <p>{report.content}</p>\n</body></html>\n\"\"\"\nwith open(\"docs/index.html\", \"w\") as f:\n    f.write(html_output)\n\nprint(\"✅ Output saved in docs/index.html and docs/output.json\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}