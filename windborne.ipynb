{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T05:37:19.904699Z",
     "iopub.status.busy": "2025-03-05T05:37:19.904259Z",
     "iopub.status.idle": "2025-03-05T05:37:34.485682Z",
     "shell.execute_reply": "2025-03-05T05:37:34.484104Z",
     "shell.execute_reply.started": "2025-03-05T05:37:19.904661Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_openai\n",
      "  Downloading langchain_openai-0.3.7-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.12)\n",
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.19-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.39 (from langchain_openai)\n",
      "  Downloading langchain_core-0.3.41-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting openai<2.0.0,>=1.58.1 (from langchain_openai)\n",
      "  Downloading openai-1.65.3-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.9.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.12)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.3)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.3)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.11.0a2)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.20-py3-none-any.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
      "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.6 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.6-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.39->langchain_openai) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.39->langchain_openai) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.39->langchain_openai) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.12)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.4->langchain) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.4->langchain) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.4->langchain) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.4->langchain) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.4->langchain) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.4->langchain) (2.4.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.29.0)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain_openai) (1.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.39->langchain_openai) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2,>=1.22.4->langchain) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2,>=1.22.4->langchain) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2,>=1.22.4->langchain) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2,>=1.22.4->langchain) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2,>=1.22.4->langchain) (2024.2.0)\n",
      "Downloading langchain_openai-0.3.7-py3-none-any.whl (55 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_community-0.3.19-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain-0.3.20-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading langchain_core-0.3.41-py3-none-any.whl (415 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m415.1/415.1 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.3.6-py3-none-any.whl (31 kB)\n",
      "Downloading openai-1.65.3-py3-none-any.whl (472 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv, httpx-sse, async-timeout, pydantic-settings, openai, langchain-core, langchain-text-splitters, langchain_openai, langchain, langchain_community\n",
      "  Attempting uninstall: async-timeout\n",
      "    Found existing installation: async-timeout 5.0.1\n",
      "    Uninstalling async-timeout-5.0.1:\n",
      "      Successfully uninstalled async-timeout-5.0.1\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.57.4\n",
      "    Uninstalling openai-1.57.4:\n",
      "      Successfully uninstalled openai-1.57.4\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.25\n",
      "    Uninstalling langchain-core-0.3.25:\n",
      "      Successfully uninstalled langchain-core-0.3.25\n",
      "  Attempting uninstall: langchain-text-splitters\n",
      "    Found existing installation: langchain-text-splitters 0.3.3\n",
      "    Uninstalling langchain-text-splitters-0.3.3:\n",
      "      Successfully uninstalled langchain-text-splitters-0.3.3\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.3.12\n",
      "    Uninstalling langchain-0.3.12:\n",
      "      Successfully uninstalled langchain-0.3.12\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed async-timeout-4.0.3 httpx-sse-0.4.0 langchain-0.3.20 langchain-core-0.3.41 langchain-text-splitters-0.3.6 langchain_community-0.3.19 langchain_openai-0.3.7 openai-1.65.3 pydantic-settings-2.8.1 python-dotenv-1.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain_openai langchain langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T05:37:34.487745Z",
     "iopub.status.busy": "2025-03-05T05:37:34.487426Z",
     "iopub.status.idle": "2025-03-05T05:37:39.580090Z",
     "shell.execute_reply": "2025-03-05T05:37:39.578849Z",
     "shell.execute_reply.started": "2025-03-05T05:37:34.487694Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch https://a.windbornesystems.com/treasure/05.json, status code: 404\n",
      "Error decoding JSON from https://a.windbornesystems.com/treasure/06.json: Extra data: line 6 column 6 (char 93)\n",
      "Error decoding JSON from https://a.windbornesystems.com/treasure/07.json: Extra data: line 6 column 6 (char 94)\n",
      "Failed to fetch https://a.windbornesystems.com/treasure/08.json, status code: 404\n",
      "Failed to fetch https://a.windbornesystems.com/treasure/09.json, status code: 404\n",
      "Failed to fetch https://a.windbornesystems.com/treasure/10.json, status code: 404\n",
      "Failed to fetch https://a.windbornesystems.com/treasure/11.json, status code: 404\n",
      "Failed to fetch https://a.windbornesystems.com/treasure/14.json, status code: 404\n",
      "Error decoding JSON from https://a.windbornesystems.com/treasure/15.json: Extra data: line 6 column 6 (char 92)\n",
      "Failed to fetch https://a.windbornesystems.com/treasure/16.json, status code: 404\n",
      "Failed to fetch https://a.windbornesystems.com/treasure/17.json, status code: 404\n",
      "Failed to fetch https://a.windbornesystems.com/treasure/18.json, status code: 404\n",
      "Failed to fetch https://a.windbornesystems.com/treasure/19.json, status code: 404\n",
      "Error decoding JSON from https://a.windbornesystems.com/treasure/20.json: Extra data: line 6 column 6 (char 93)\n",
      "Failed to fetch https://a.windbornesystems.com/treasure/21.json, status code: 404\n",
      "Error decoding JSON from https://a.windbornesystems.com/treasure/22.json: Extra data: line 6 column 6 (char 95)\n",
      "Failed to fetch https://a.windbornesystems.com/treasure/23.json, status code: 404\n",
      "Data Shape (after full interpolation): (7, 1000, 3)\n",
      "Any NaN remaining? False\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from scipy.interpolate import interp1d\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def fetch_windborne_data(hours=24):\n",
    "    all_data = {}\n",
    "    for h in range(hours):\n",
    "        url = f\"https://a.windbornesystems.com/treasure/{h:02d}.json\"\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            try:\n",
    "                data = response.json()\n",
    "                if isinstance(data, list) and all(isinstance(item, list) and len(item) == 3 for item in data):\n",
    "                    all_data[h] = np.array(data)\n",
    "                else:\n",
    "                    print(f\"Warning: Skipping malformed data from {url}\")\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON from {url}: {e}\")\n",
    "        else:\n",
    "            print(f\"Failed to fetch {url}, status code: {response.status_code}\")\n",
    "\n",
    "    if not all_data:\n",
    "        print(\"No valid data collected.\")\n",
    "        return None\n",
    "    \n",
    "    # Ensure data is structured as (hours, balloons, coordinates) only for existing hours\n",
    "    num_balloons = max(arr.shape[0] for arr in all_data.values())\n",
    "    structured_data = np.full((len(all_data), num_balloons, 3), np.nan)\n",
    "    \n",
    "    for i, (h, data) in enumerate(all_data.items()):\n",
    "        structured_data[i, :data.shape[0], :] = data\n",
    "    \n",
    "    # Fill missing values with column mean\n",
    "    for d in range(3):  # Iterate over x, y, z coordinates\n",
    "        valid_mask = ~np.isnan(structured_data[:, :, d])\n",
    "        if valid_mask.any():  # If at least one valid value exists\n",
    "            mean_value = np.nanmean(structured_data[:, :, d])\n",
    "            structured_data[:, :, d] = np.where(np.isnan(structured_data[:, :, d]), mean_value, structured_data[:, :, d])\n",
    "    \n",
    "    return structured_data\n",
    "\n",
    "all_positions = fetch_windborne_data()\n",
    "\n",
    "if all_positions is not None:\n",
    "    print(\"Data Shape (after full interpolation):\", all_positions.shape)\n",
    "    print(\"Any NaN remaining?\", np.isnan(all_positions).any())\n",
    "else:\n",
    "    print(\"No valid data available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T05:37:39.582657Z",
     "iopub.status.busy": "2025-03-05T05:37:39.582253Z",
     "iopub.status.idle": "2025-03-05T05:38:28.024347Z",
     "shell.execute_reply": "2025-03-05T05:38:28.023059Z",
     "shell.execute_reply.started": "2025-03-05T05:37:39.582627Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Input Shape: (2000, 5, 3)\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.3026 - val_loss: 0.1386\n",
      "Epoch 2/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0897 - val_loss: 0.0384\n",
      "Epoch 3/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0365 - val_loss: 0.0298\n",
      "Epoch 4/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0296 - val_loss: 0.0195\n",
      "Epoch 5/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0208 - val_loss: 0.0174\n",
      "Epoch 6/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0157 - val_loss: 0.0198\n",
      "Epoch 7/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0137 - val_loss: 0.0143\n",
      "Epoch 8/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0124 - val_loss: 0.0152\n",
      "Epoch 9/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0125 - val_loss: 0.0180\n",
      "Epoch 10/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0130 - val_loss: 0.0132\n",
      "Epoch 11/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0119 - val_loss: 0.0123\n",
      "Epoch 12/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0117 - val_loss: 0.0101\n",
      "Epoch 13/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0092 - val_loss: 0.0097\n",
      "Epoch 14/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0110 - val_loss: 0.0100\n",
      "Epoch 15/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0092 - val_loss: 0.0103\n",
      "Epoch 16/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0103 - val_loss: 0.0123\n",
      "Epoch 17/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0091 - val_loss: 0.0108\n",
      "Epoch 18/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0097 - val_loss: 0.0106\n",
      "Epoch 19/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0087 - val_loss: 0.0121\n",
      "Epoch 20/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0076 - val_loss: 0.0106\n",
      "Epoch 21/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0078 - val_loss: 0.0101\n",
      "Epoch 22/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0076 - val_loss: 0.0099\n",
      "Epoch 23/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0082 - val_loss: 0.0092\n",
      "Epoch 24/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0081 - val_loss: 0.0105\n",
      "Epoch 25/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0074 - val_loss: 0.0092\n",
      "Epoch 26/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0049 - val_loss: 0.0102\n",
      "Epoch 27/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0088 - val_loss: 0.0102\n",
      "Epoch 28/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 29/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0071 - val_loss: 0.0099\n",
      "Epoch 30/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0092 - val_loss: 0.0084\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "Mean Squared Error (MSE): 0.006445\n",
      "R² Score: 0.967793\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def process_sequences(data, time_steps=5):\n",
    "    \"\"\"Prepare LSTM sequences for training, ensuring correct order.\"\"\"\n",
    "    num_balloons = data.shape[1]\n",
    "    X, y = [], []\n",
    "    scalers = [MinMaxScaler() for _ in range(num_balloons)]\n",
    "\n",
    "    for i in range(num_balloons):\n",
    "        balloon_data = data[:, i, :][::-1]  # Reverse order: [08, 07, ..., 00]\n",
    "        balloon_data = scalers[i].fit_transform(balloon_data)\n",
    "\n",
    "        # Generate time-step sequences\n",
    "        for j in range(len(balloon_data) - time_steps):\n",
    "            X.append(balloon_data[j:j+time_steps])\n",
    "            y.append(balloon_data[j+time_steps])\n",
    "\n",
    "    return np.array(X), np.array(y), scalers\n",
    "\n",
    "# Prepare LSTM sequences\n",
    "time_steps = 5\n",
    "X, y, scalers = process_sequences(all_positions, time_steps)\n",
    "print(\"LSTM Input Shape:\", X.shape)  # Expected: (num_samples, time_steps, 3)\n",
    "\n",
    "# Define Early Stopping\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "\n",
    "# Define LSTM Model\n",
    "model = Sequential([\n",
    "    LSTM(64, return_sequences=True, activation=\"relu\", input_shape=(time_steps, 3)),\n",
    "    LSTM(32, return_sequences=False, activation=\"relu\"),\n",
    "    Dense(16, activation=\"relu\"),\n",
    "    Dense(3)  # Predicts (lat, lon, alt)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001, clipnorm=1.0), loss=\"mse\")\n",
    "\n",
    "# Train Model\n",
    "history = model.fit(X, y, epochs=30, batch_size=16, validation_split=0.1, callbacks=[early_stop])\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "mse = mean_squared_error(y.reshape(-1, 3), y_pred.reshape(-1, 3))\n",
    "r2 = r2_score(y.reshape(-1, 3), y_pred.reshape(-1, 3))\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse:.6f}\")\n",
    "print(f\"R² Score: {r2:.6f}\")\n",
    "\n",
    "def predict_next_position(model, all_positions, scalers, time_steps=5):\n",
    "    \"\"\"Predict the next step using the latest available data from each balloon.\"\"\"\n",
    "    num_balloons = len(scalers)\n",
    "    predicted_next_real = []\n",
    "\n",
    "    for i in range(num_balloons):\n",
    "        balloon_data = all_positions[:, i, :][::-1]  # Reverse to get the latest first\n",
    "        balloon_data_scaled = scalers[i].transform(balloon_data)\n",
    "        latest_sequence = balloon_data_scaled[:time_steps].reshape(1, time_steps, 3)\n",
    "\n",
    "        predicted_scaled = model.predict(latest_sequence, verbose=0)\n",
    "        predicted_real = scalers[i].inverse_transform(predicted_scaled)\n",
    "        predicted_next_real.append(predicted_real)\n",
    "\n",
    "    return np.array(predicted_next_real)\n",
    "\n",
    "# Predict the next time step\n",
    "predicted_next_position = predict_next_position(model, all_positions, scalers, time_steps)\n",
    "\n",
    "print(\"Predicted Next Positions (Lat, Lon, Alt):\")\n",
    "print(predicted_next_position)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-05T05:45:57.922134Z",
     "iopub.status.busy": "2025-03-05T05:45:57.921674Z",
     "iopub.status.idle": "2025-03-05T05:45:59.558910Z",
     "shell.execute_reply": "2025-03-05T05:45:59.557582Z",
     "shell.execute_reply.started": "2025-03-05T05:45:57.922100Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Spatial clusters indicating wind patterns: By analyzing the data of balloon positions over 24 hours, we can identify spatial clusters that indicate wind patterns. These clusters may help in understanding the direction and intensity of winds at different altitudes.\n",
      "\n",
      "- Anomalies: There do not seem to be any significant anomalies in the data, indicating that the balloons are not stuck in one particular area or facing any unexpected issues during the 24-hour period. This suggests that the balloon launches are functioning smoothly.\n",
      "\n",
      "- Suggestions for optimizing future launches: Based on the LSTM predictions for the next positions of the balloons, we can optimize future launches by adjusting the launch locations or timings to minimize travel time and maximize data collection efficiency. Additionally, utilizing the spatial clusters identified in the data can help in planning more strategic launch locations to gather diverse weather data.\n"
     ]
    }
   ],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if OPENAI_API_KEY is None:\n",
    "    raise ValueError(\"❌ OPENAI_API_KEY is not set. Check your GitHub Secrets.\")\n",
    "\n",
    "template = \"\"\"You are an operational analyst for a weather balloon company. Analyze the data of \n",
    "balloon positions over 24H: {all_positions}, LSTM prediction: {LSTM prediction}, pred next position: {pred next position}\n",
    "\n",
    "Extract 3 key insights, such as:\n",
    "- Spatial clusters indicating wind patterns\n",
    "- Anomalies (e.g., balloons stuck in one area)\n",
    "- Suggestions for optimizing future launches\n",
    "Format the response as a bullet-point report.\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# Generate insights\n",
    "chain = prompt | model\n",
    "report = chain.invoke({\"all_positions\": str(all_positions), \"LSTM prediction\": str(y_pred), \"pred next position\": str(predicted_next_position)})\n",
    "print(report.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "insights_text = report.content if isinstance(report.content, str) else str(report.content)\n",
    "\n",
    "html_output = f\"\"\"\n",
    "<html><head><title>Windborne Balloon Analysis</title></head>\n",
    "<body>\n",
    "    <h1>Windborne Balloon Analysis</h1>\n",
    "    <p><strong>Mean Squared Error (MSE):</strong> {mse:.6f}</p>\n",
    "    <p><strong>R² Score:</strong> {r2:.6f}</p>\n",
    "    <h2>Predicted Next Position:</h2>\n",
    "    <pre>{predicted_next_position.tolist()}</pre>\n",
    "    <h2>Insights:</h2>\n",
    "    <pre>{insights_text}</pre>  <!-- Ensures correct display -->\n",
    "</body></html>\n",
    "\"\"\"\n",
    "\n",
    "# Write HTML file\n",
    "with open(\"docs/index.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(html_output)\n",
    "\n",
    "print(\"✅ Output saved in docs/index.html\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
